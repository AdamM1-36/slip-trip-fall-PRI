{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è TensorRT requires GPU export, automatically assigning device=0\n",
      "Ultralytics 8.3.20 üöÄ Python-3.11.10 torch-2.5.0+cu124 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "YOLO11n-pose summary (fused): 257 layers, 2,866,468 parameters, 0 gradients, 7.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '../yolo11n-pose.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 56, 8400) (6.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.35...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 1.4s, saved as '../yolo11n-pose.onnx' (11.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 10.3.0...\n",
      "[10/29/2024-01:39:23] [TRT] [I] [MemUsageChange] Init CUDA: CPU +1, GPU +0, now: CPU 794, GPU 1190 (MiB)\n",
      "[10/29/2024-01:39:32] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +2090, GPU +386, now: CPU 3040, GPU 1576 (MiB)\n",
      "[10/29/2024-01:39:32] [TRT] [I] ----------------------------------------------------------------\n",
      "[10/29/2024-01:39:32] [TRT] [I] Input filename:   ../yolo11n-pose.onnx\n",
      "[10/29/2024-01:39:32] [TRT] [I] ONNX IR version:  0.0.10\n",
      "[10/29/2024-01:39:32] [TRT] [I] Opset version:    19\n",
      "[10/29/2024-01:39:32] [TRT] [I] Producer name:    pytorch\n",
      "[10/29/2024-01:39:32] [TRT] [I] Producer version: 2.5.0\n",
      "[10/29/2024-01:39:32] [TRT] [I] Domain:           \n",
      "[10/29/2024-01:39:32] [TRT] [I] Model version:    0\n",
      "[10/29/2024-01:39:32] [TRT] [I] Doc string:       \n",
      "[10/29/2024-01:39:32] [TRT] [I] ----------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(1, 3, 640, 640) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(1, 56, 8400) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP16 engine as ../yolo11n-pose.engine\n",
      "[10/29/2024-01:39:32] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[10/29/2024-01:43:49] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[10/29/2024-01:43:52] [TRT] [I] Total Host Persistent Memory: 539504\n",
      "[10/29/2024-01:43:52] [TRT] [I] Total Device Persistent Memory: 2048\n",
      "[10/29/2024-01:43:52] [TRT] [I] Total Scratch Memory: 2764800\n",
      "[10/29/2024-01:43:52] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 192 steps to complete.\n",
      "[10/29/2024-01:43:52] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 15.3908ms to assign 11 blocks to 192 nodes requiring 14049280 bytes.\n",
      "[10/29/2024-01:43:52] [TRT] [I] Total Activation Memory: 14048256\n",
      "[10/29/2024-01:43:52] [TRT] [I] Total Weights Memory: 6168644\n",
      "[10/29/2024-01:43:52] [TRT] [I] Engine generation completed in 260.586 seconds.\n",
      "[10/29/2024-01:43:52] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 133 MiB\n",
      "[10/29/2024-01:43:52] [TRT] [I] [MemUsageStats] Peak memory usage during Engine building and serialization: CPU: 4951 MiB\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success ‚úÖ 271.3s, saved as '../yolo11n-pose.engine' (13.2 MB)\n",
      "\n",
      "Export complete (272.8s)\n",
      "Results saved to \u001b[1m/home/adamm1/_Programming/python/slip-trip-fall-PRI\u001b[0m\n",
      "Predict:         yolo predict task=pose model=../yolo11n-pose.engine imgsz=640 half \n",
      "Validate:        yolo val task=pose model=../yolo11n-pose.engine imgsz=640 data=/ultralytics/ultralytics/cfg/datasets/coco-pose.yaml half \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../yolo11n-pose.engine'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('../yolo11n-pose.pt')\n",
    "\n",
    "model.export(\n",
    "    format='engine',\n",
    "    half=True,\n",
    "    imgsz=640,\n",
    "    workspace=8,\n",
    "    # batch=8,\n",
    "    # int8=True,\n",
    "    # data='coco-pose.yaml',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3x speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading yolo11n-pose.engine for TensorRT inference...\n",
      "[10/29/2024-01:13:31] [TRT] [I] The logger passed into createInferRuntime differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.\n",
      "[10/29/2024-01:13:31] [TRT] [I] Loaded engine size: 12 MiB\n",
      "[10/29/2024-01:13:31] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +1, GPU +18, now: CPU 3, GPU 94 (MiB)\n",
      "\n",
      "0: 640x640 3 persons, 8.3ms\n",
      "Speed: 2.6ms preprocess, 8.3ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 9.5ms\n",
      "Speed: 2.0ms preprocess, 9.5ms inference, 6.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 9.5ms\n",
      "Speed: 1.5ms preprocess, 9.5ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 9.4ms\n",
      "Speed: 1.7ms preprocess, 9.4ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 11.6ms\n",
      "Speed: 1.5ms preprocess, 11.6ms inference, 5.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 10.8ms\n",
      "Speed: 1.7ms preprocess, 10.8ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 10.9ms\n",
      "Speed: 1.4ms preprocess, 10.9ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 11.4ms\n",
      "Speed: 1.4ms preprocess, 11.4ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 12.0ms\n",
      "Speed: 1.5ms preprocess, 12.0ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 10.8ms\n",
      "Speed: 1.6ms preprocess, 10.8ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 11.0ms\n",
      "Speed: 1.5ms preprocess, 11.0ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 9.6ms\n",
      "Speed: 1.4ms preprocess, 9.6ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 10.6ms\n",
      "Speed: 1.6ms preprocess, 10.6ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 9.7ms\n",
      "Speed: 1.6ms preprocess, 9.7ms inference, 6.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 11.6ms\n",
      "Speed: 1.4ms preprocess, 11.6ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 12.8ms\n",
      "Speed: 2.2ms preprocess, 12.8ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 11.9ms\n",
      "Speed: 1.8ms preprocess, 11.9ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 11.2ms\n",
      "Speed: 1.6ms preprocess, 11.2ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 11.8ms\n",
      "Speed: 1.7ms preprocess, 11.8ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 11.7ms\n",
      "Speed: 1.8ms preprocess, 11.7ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 10.7ms\n",
      "Speed: 1.5ms preprocess, 10.7ms inference, 6.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 11.0ms\n",
      "Speed: 1.5ms preprocess, 11.0ms inference, 5.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 11.2ms\n",
      "Speed: 1.7ms preprocess, 11.2ms inference, 5.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 10.7ms\n",
      "Speed: 1.5ms preprocess, 10.7ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 10.7ms\n",
      "Speed: 1.5ms preprocess, 10.7ms inference, 6.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 10.6ms\n",
      "Speed: 1.7ms preprocess, 10.6ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 11.4ms\n",
      "Speed: 2.1ms preprocess, 11.4ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 10.7ms\n",
      "Speed: 1.6ms preprocess, 10.7ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 10.4ms\n",
      "Speed: 1.9ms preprocess, 10.4ms inference, 6.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 11.1ms\n",
      "Speed: 1.8ms preprocess, 11.1ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 10.5ms\n",
      "Speed: 1.5ms preprocess, 10.5ms inference, 7.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 11.1ms\n",
      "Speed: 1.6ms preprocess, 11.1ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 10.5ms\n",
      "Speed: 1.5ms preprocess, 10.5ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 10.3ms\n",
      "Speed: 1.5ms preprocess, 10.3ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 11.2ms\n",
      "Speed: 2.0ms preprocess, 11.2ms inference, 5.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 11.0ms\n",
      "Speed: 1.5ms preprocess, 11.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 12.0ms\n",
      "Speed: 1.9ms preprocess, 12.0ms inference, 5.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 11.4ms\n",
      "Speed: 1.6ms preprocess, 11.4ms inference, 6.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 11.4ms\n",
      "Speed: 2.0ms preprocess, 11.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 11.2ms\n",
      "Speed: 1.4ms preprocess, 11.2ms inference, 5.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 11.2ms\n",
      "Speed: 1.6ms preprocess, 11.2ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 12.2ms\n",
      "Speed: 1.9ms preprocess, 12.2ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 11.3ms\n",
      "Speed: 1.5ms preprocess, 11.3ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 10.8ms\n",
      "Speed: 1.9ms preprocess, 10.8ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 11.0ms\n",
      "Speed: 1.6ms preprocess, 11.0ms inference, 6.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 10.6ms\n",
      "Speed: 1.6ms preprocess, 10.6ms inference, 5.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 12.3ms\n",
      "Speed: 2.3ms preprocess, 12.3ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 12.2ms\n",
      "Speed: 2.1ms preprocess, 12.2ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 15.7ms\n",
      "Speed: 2.1ms preprocess, 15.7ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 15.8ms\n",
      "Speed: 2.1ms preprocess, 15.8ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 persons, 13.2ms\n",
      "Speed: 2.2ms preprocess, 13.2ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "tensorrt_model = YOLO('../yolo11n-pose.engine')\n",
    "video_path = '../fall_dataset/videos/video_2.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened:\n",
    "    print(\"Error could not open video\")\n",
    "    exit()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    results = tensorrt_model(frame)\n",
    "    for result in results:\n",
    "        frame = result.plot()\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
